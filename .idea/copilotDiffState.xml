<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README.md" />
              <option name="originalContent" value="&lt;h1 align=&quot;center&quot;&gt; Sanex&lt;/h1&gt;&#10;&#10;&lt;div align=&quot;center&quot;&gt;&#10;&#10;[![PyPI version](https://img.shields.io/pypi/v/sanex.svg)](https://pypi.org/project/sanex/)&#10;[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)&#10;[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)&#10;[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)&#10;&#10;&lt;/div&gt;&#10;&#10;**Sanex** is a comprehensive, high-performance data cleaning and preprocessing library for Python, designed to work seamlessly with both **pandas** and **polars** DataFrames. With its intuitive, chainable API, Sanex transforms the traditionally tedious process of data cleaning into an elegant, readable workflow.&#10;&#10;---&#10;&#10;##  Key Features&#10;&#10;- ** Fluent, Chainable API**: Clean your data in a single, readable chain of commands&#10;- **⚡ Dual Backend Support**: Works effortlessly with both pandas and polars DataFrames&#10;- ** Comprehensive Cleaning**: From basic cleaning to advanced data extraction and transformation&#10;- ** Intelligent Outlier Detection**: Multiple methods including IQR and Z-score analysis&#10;- ** Advanced Data Extraction**: Extract emails, phone numbers, and custom patterns with regex&#10;- ** Smart Type Handling**: Automatic type inference and standardization&#10;- ** Performance Optimized**: Designed for speed and memory efficiency&#10;- ** Extensible**: Easily add custom cleaning functions to your pipeline&#10;&#10;---&#10;&#10;##  Installation&#10;&#10;Install Sanex easily with pip:&#10;&#10;```bash&#10;pip install sanex&#10;```&#10;&#10;**Requirements:**&#10;- Python 3.8+&#10;- pandas &gt;= 1.0&#10;- polars &gt;= 0.19&#10;&#10;---&#10;&#10;## ⚡ Quick Start&#10;&#10;Here's how to transform messy data into clean, analysis-ready datasets:&#10;&#10;```python&#10;import pandas as pd&#10;import sanex as sx&#10;&#10;# Create a messy sample dataset&#10;data = {&#10;    'First Name': ['  John  ', 'Jane', '  Peter', 'JOHN', None],&#10;    'Last Name': ['Smith', 'Doe', 'Jones', 'Smith', 'Brown'],&#10;    'Age': [28, 34, None, 28, 45],&#10;    'Email': ['john@email.com', 'invalid-email', 'peter@test.org', 'john@email.com', None],&#10;    'Phone': ['123-456-7890', '(555) 123-4567', 'not-a-phone', '123.456.7890', '+1-800-555-0199'],&#10;    'Salary': ['$70,000', '80000', '$65,000.50', '$70,000', '€75,000'],&#10;    'Active': ['True', 'False', 'yes', 'TRUE', 'N'],&#10;    'Notes': ['  Important client  ', '', '   Follow up   ', None, 'VIP']&#10;}&#10;df = pd.DataFrame(data)&#10;&#10;# Clean the entire dataset with a single chain&#10;clean_df = (&#10;    sx(df)&#10;    .clean_column_names()                    # Standardize column names&#10;    .fill_missing(value='Unknown')           # Fill missing values&#10;    .remove_whitespace()                     # Clean whitespace&#10;    .remove_duplicates()                     # Remove duplicate rows&#10;    .standardize_booleans()                  # Convert boolean-like values&#10;    .extract_email()                         # Extract email addresses&#10;    .extract_phone_numbers()                 # Extract phone numbers&#10;    .extract_and_clean_numeric()             # Extract numeric values from strings&#10;    .drop_single_value_columns()             # Remove columns with only one value&#10;    .remove_outliers(method='iqr')           # Handle outliers&#10;    .to_df()                                 # Return the cleaned DataFrame&#10;)&#10;&#10;print(clean_df.head())&#10;```&#10;&#10;---&#10;&#10;##  Complete API Reference&#10;&#10;### ️ Initialization&#10;&#10;```python&#10;import sanex as sx&#10;&#10;# Initialize with any DataFrame&#10;cleaner = sx(df)  # Works with pandas or polars DataFrames&#10;```&#10;&#10;###  Column Name Standardization&#10;&#10;Transform column names to consistent formats:&#10;&#10;```python&#10;# General column cleaning with case conversion&#10;.clean_column_names(case='snake')  # Options: 'snake', 'camel', 'pascal', 'kebab', 'title', 'lower', 'screaming_snake'&#10;&#10;# Specific case conversions&#10;.snakecase()                       # column_name&#10;.camelcase()                       # columnName  &#10;.pascalcase()                      # ColumnName&#10;.kebabcase()                       # column-name&#10;.titlecase()                       # Column Name&#10;.lowercase()                       # column name&#10;.screaming_snakecase()             # COLUMN_NAME&#10;```&#10;&#10;###  Data Deduplication&#10;&#10;Remove duplicate data efficiently:&#10;&#10;```python&#10;.remove_duplicates()               # Remove duplicate rows across all columns&#10;```&#10;&#10;### ❌ Missing Data Management&#10;&#10;Handle missing values with precision:&#10;&#10;```python&#10;# Fill missing values&#10;.fill_missing(value=0)                           # Fill all columns with 0&#10;.fill_missing(value='Unknown', subset=['name'])  # Fill specific columns&#10;&#10;# Drop missing values&#10;.drop_missing()                                  # Drop rows with any missing values&#10;.drop_missing(how='all')                         # Drop rows where all values are missing&#10;.drop_missing(thresh=3)                          # Keep rows with at least 3 non-null values&#10;.drop_missing(axis='columns')                    # Drop columns with missing values&#10;.drop_missing(subset=['name', 'email'])          # Consider only specific columns&#10;```&#10;&#10;###  Text and Whitespace Cleaning&#10;&#10;Clean and standardize text data:&#10;&#10;```python&#10;.remove_whitespace()                             # Remove leading/trailing whitespace&#10;.replace_text('old', 'new')                      # Replace text in all columns&#10;.replace_text('old', 'new', subset=['name'])     # Replace in specific columns&#10;.remove_punctuation()                            # Remove punctuation marks&#10;.remove_punctuation(subset=['description'])      # Remove from specific columns&#10;```&#10;&#10;### ️ Column Management&#10;&#10;Manage DataFrame structure:&#10;&#10;```python&#10;.drop_single_value_columns()                     # Remove columns with only one unique value&#10;.remove_unwanted_rows_and_cols()                 # Remove rows/cols with unwanted values&#10;.remove_unwanted_rows_and_cols(                  # Custom unwanted values&#10;    unwanted_values=['', 'N/A', 'NULL']&#10;)&#10;```&#10;&#10;###  Outlier Detection and Handling&#10;&#10;Sophisticated outlier management:&#10;&#10;```python&#10;# General outlier handling&#10;.handle_outliers()                               # Default: IQR method, factor=1.5&#10;.handle_outliers(method='zscore', factor=2.0)    # Z-score method&#10;.handle_outliers(subset=['salary', 'age'])       # Specific columns only&#10;&#10;# Cap outliers (replace with threshold values)&#10;.cap_outliers()                                  # Cap using IQR method&#10;.cap_outliers(method='zscore', factor=2.5)       # Cap using Z-score&#10;&#10;# Remove outlier rows entirely&#10;.remove_outliers()                               # Remove rows with outliers&#10;.remove_outliers(method='iqr', factor=1.5)       # Custom parameters&#10;```&#10;&#10;**Outlier Detection Methods:**&#10;- **IQR (Interquartile Range)**: `Q1 - factor*IQR` to `Q3 + factor*IQR`&#10;- **Z-Score**: Values beyond `factor` standard deviations from the mean&#10;&#10;###  Data Type Standardization&#10;&#10;Convert and standardize data types:&#10;&#10;```python&#10;# Boolean standardization&#10;.standardize_booleans()                          # Convert 'yes/no', 'true/false', etc.&#10;.standardize_booleans(&#10;    true_values=['yes', 'y', '1', 'true'],       # Custom true values&#10;    false_values=['no', 'n', '0', 'false'],     # Custom false values  &#10;    columns=['active', 'verified']              # Specific columns&#10;)&#10;```&#10;&#10;**Default Boolean Mappings:**&#10;- **True**: 'true', '1', 't', 'yes', 'y', 'on'&#10;- **False**: 'false', '0', 'f', 'no', 'n', 'off'&#10;&#10;###  Advanced Data Extraction&#10;&#10;Extract structured data from unstructured text:&#10;&#10;```python&#10;# Email extraction&#10;.extract_email()                                 # Extract emails from all columns&#10;.extract_email(subset=['contact_info'])          # From specific columns&#10;&#10;# Phone number extraction  &#10;.extract_phone_numbers()                         # Extract phone numbers&#10;.extract_phone_numbers(subset=['contact'])       # From specific columns&#10;&#10;# Numeric data extraction and cleaning&#10;.extract_and_clean_numeric()                     # Extract numbers from text&#10;.extract_and_clean_numeric(subset=['prices'])    # From specific columns&#10;&#10;# Custom regex extraction (interactive)&#10;.extract_with_regex()                            # Prompts for regex pattern&#10;.extract_with_regex(subset=['text_column'])      # From specific columns&#10;&#10;# Combined numeric cleaning&#10;.clean_numeric()                                 # Extract + outlier handling&#10;.clean_numeric(method='zscore', factor=2.0)      # Custom outlier parameters&#10;```&#10;&#10;###  Output&#10;&#10;```python&#10;.to_df()                                         # Return the cleaned DataFrame&#10;```&#10;&#10;---&#10;&#10;##  Advanced Usage Examples&#10;&#10;### Real-World Data Cleaning Pipeline&#10;&#10;```python&#10;import pandas as pd&#10;import sanex as sx&#10;&#10;# Load messy customer data&#10;df = pd.read_csv('messy_customer_data.csv')&#10;&#10;# Comprehensive cleaning pipeline&#10;clean_customers = (&#10;    sx(df)&#10;    .clean_column_names(case='snake')           # Standardize column names&#10;    .fill_missing(value='Not Provided')        # Handle missing data&#10;    .remove_whitespace()                        # Clean text&#10;    .standardize_booleans(                      # Standardize boolean columns&#10;        columns=['is_active', 'newsletter_opt_in']&#10;    )&#10;    .extract_email(subset=['contact_info'])     # Extract emails&#10;    .extract_phone_numbers(subset=['contact_info'])  # Extract phone numbers&#10;    .extract_and_clean_numeric(subset=['revenue', 'age'])  # Clean numeric data&#10;    .remove_outliers(                           # Handle outliers in revenue&#10;        method='iqr', &#10;        factor=2.0,&#10;        subset=['revenue']&#10;    )&#10;    .drop_single_value_columns()                # Remove useless columns&#10;    .remove_duplicates()                        # Final deduplication&#10;    .to_df()&#10;)&#10;```&#10;&#10;### Financial Data Processing&#10;&#10;```python&#10;# Clean financial transaction data&#10;financial_clean = (&#10;    sx(transactions_df)&#10;    .clean_column_names(case='snake')&#10;    .fill_missing(value=0, subset=['amount'])&#10;    .extract_and_clean_numeric(subset=['amount', 'fee'])&#10;    .standardize_booleans(subset=['is_recurring'])&#10;    .cap_outliers(method='zscore', factor=3.0, subset=['amount'])&#10;    .remove_whitespace()&#10;    .to_df()&#10;)&#10;```&#10;&#10;### Survey Data Standardization&#10;&#10;```python&#10;# Clean survey responses&#10;survey_clean = (&#10;    sx(survey_df)&#10;    .clean_column_names(case='snake')&#10;    .standardize_booleans(&#10;        true_values=['Yes', 'Y', 'Agree', 'True', '1'],&#10;        false_values=['No', 'N', 'Disagree', 'False', '0']&#10;    )&#10;    .fill_missing(value='No Response')&#10;    .remove_whitespace()&#10;    .drop_single_value_columns()&#10;    .to_df()&#10;)&#10;```&#10;&#10;---&#10;&#10;##  Method Chaining Benefits&#10;&#10;Sanex's chainable API provides several advantages:&#10;&#10;1. **Readability**: Each step is clear and self-documenting&#10;2. **Maintainability**: Easy to add, remove, or reorder operations&#10;3. **Performance**: Optimized internal operations reduce memory overhead&#10;4. **Flexibility**: Mix and match operations based on your data's needs&#10;&#10;```python&#10;# Traditional approach (verbose and hard to follow)&#10;df = remove_duplicates(df)&#10;df = fill_missing(df, value='Unknown')&#10;df = standardize_booleans(df)&#10;df = remove_outliers(df, method='iqr')&#10;&#10;# Sanex approach (clean and readable)&#10;df = (sx(df)&#10;      .remove_duplicates()&#10;      .fill_missing(value='Unknown')&#10;      .standardize_booleans()&#10;      .remove_outliers(method='iqr')&#10;      .to_df())&#10;```&#10;&#10;---&#10;&#10;##  Performance Tips&#10;&#10;1. **Use polars for large datasets** - Sanex automatically optimizes for polars' performance&#10;2. **Chain operations efficiently** - Sanex minimizes intermediate copies&#10;3. **Specify subsets** - Process only the columns you need&#10;4. **Choose appropriate outlier methods** - IQR is faster, Z-score is more sensitive&#10;&#10;```python&#10;# Performance-optimized pipeline&#10;result = (&#10;    sx(large_df)&#10;    .remove_duplicates()                        # Early deduplication saves memory&#10;    .drop_single_value_columns()                # Remove unnecessary columns first&#10;    .fill_missing(value=0, subset=['numeric_cols'])  # Target specific columns&#10;    .remove_outliers(method='iqr', subset=['revenue'])  # IQR is faster than zscore&#10;    .to_df()&#10;)&#10;```&#10;&#10;---&#10;&#10;##  Testing and Quality Assurance&#10;&#10;Sanex includes comprehensive test coverage with 86+ test cases covering:&#10;&#10;- ✅ pandas and polars compatibility&#10;- ✅ Edge cases and error handling  &#10;- ✅ Performance optimization&#10;- ✅ Data integrity preservation&#10;- ✅ Type safety and validation&#10;&#10;Run tests locally:&#10;```bash&#10;git clone https://github.com/johntocci/sanex&#10;cd sanex&#10;pip install -e .[dev]&#10;pytest tests/&#10;```&#10;&#10;---&#10;&#10;##  Contributing&#10;&#10;We welcome contributions! Sanex is designed to be extensible and community-driven.&#10;&#10;### How to Contribute&#10;&#10;1. **Fork the repository** on GitHub&#10;2. **Create a feature branch**: `git checkout -b feature/amazing-feature`&#10;3. **Add your changes** with comprehensive tests&#10;4. **Follow the coding standards** (black formatting, type hints)&#10;5. **Run the test suite**: `pytest tests/`&#10;6. **Submit a pull request** with a clear description&#10;&#10;### Development Setup&#10;&#10;```bash&#10;# Clone and setup development environment&#10;git clone https://github.com/johntocci/sanex&#10;cd sanex&#10;pip install -e .[dev]&#10;&#10;# Run tests&#10;pytest tests/&#10;&#10;# Format code&#10;black src/ tests/&#10;```&#10;&#10;### Adding New Functions&#10;&#10;Sanex's modular architecture makes it easy to add new cleaning functions:&#10;&#10;1. Create your function in `src/sanex/functions/`&#10;2. Add it to the imports in `src/sanex/functions/__init__.py`&#10;3. Add a corresponding method to the `Sanex` class&#10;4. Write comprehensive tests in `tests/`&#10;&#10;---&#10;&#10;##  Changelog&#10;&#10;### Version 0.2.0&#10;- ✨ Added comprehensive data extraction capabilities&#10;- ✨ Enhanced outlier detection with multiple methods&#10;- ✨ Improved text processing and punctuation removal&#10;-  Fixed boolean standardization edge cases&#10;-  Resolved missing data handling in complex workflows&#10;- ⚡ Performance optimizations for large datasets&#10;-  Comprehensive documentation updates&#10;&#10;### Version 0.1.0&#10;-  Initial release with core cleaning functionality&#10;-  Chainable API implementation&#10;-  pandas and polars support&#10;&#10;---&#10;&#10;##  License&#10;&#10;This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.&#10;&#10;---&#10;&#10;##  Acknowledgments&#10;&#10;- Built with ❤️ for the data science community&#10;- Inspired by the need for simple, powerful data cleaning tools&#10;- Thanks to all contributors and users who help improve Sanex&#10;&#10;---&#10;&#10;&lt;div align=&quot;center&quot;&gt;&#10;&#10;**Made with ❤️ by [John Tocci](https://github.com/johntocci)**&#10;&#10;[⭐ Star us on GitHub](https://github.com/johntocci/sanex) | [ Report Issues](https://github.com/johntocci/sanex/issues) | [ Request Features](https://github.com/johntocci/sanex/issues)&#10;&#10;&lt;/div&gt;&#10;" />
              <option name="updatedContent" value="&lt;h1 align=&quot;center&quot;&gt; Sanex&lt;/h1&gt;&#10;&#10;&lt;div align=&quot;center&quot;&gt;&#10;&#10;[![PyPI version](https://img.shields.io/pypi/v/sanex.svg)](https://pypi.org/project/sanex/)&#10;[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)&#10;[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)&#10;[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)&#10;&#10;&lt;/div&gt;&#10;&#10;**Sanex** is a comprehensive, high-performance data cleaning and preprocessing library for Python, designed to work seamlessly with both **pandas** and **polars** DataFrames. With its intuitive, chainable API, Sanex transforms the traditionally tedious process of data cleaning into an elegant, readable workflow.&#10;&#10;---&#10;&#10;##  Key Features&#10;&#10;- ** Fluent, Chainable API**: Clean your data in a single, readable chain of commands&#10;- **⚡ Dual Backend Support**: Works effortlessly with both pandas and polars DataFrames&#10;- ** Comprehensive Cleaning**: From basic cleaning to advanced data extraction and transformation&#10;- ** Display Formatting Pipeline**: Format columns for presentation (currency, percentages, thousands separators, date formatting, truncation, title-cased headers)&#10;- ** Intelligent Outlier Detection**: Multiple methods including IQR and Z-score analysis&#10;- ** Advanced Data Extraction**: Extract emails, phone numbers, and custom patterns with regex&#10;- ** Smart Type Handling**: Automatic type inference and standardization&#10;- ** Performance Optimized**: Designed for speed and memory efficiency&#10;- ** Extensible**: Easily add custom cleaning functions to your pipeline&#10;&#10;---&#10;&#10;##  Installation&#10;&#10;Install Sanex easily with pip:&#10;&#10;```bash&#10;pip install sanex&#10;```&#10;&#10;**Requirements:**&#10;- Python 3.8+&#10;- pandas &gt;= 1.0&#10;- polars &gt;= 0.19&#10;&#10;---&#10;&#10;## ⚡ Quick Start&#10;&#10;Here's how to transform messy data into clean, analysis-ready datasets:&#10;&#10;```python&#10;import pandas as pd&#10;import sanex as sx&#10;&#10;# Create a messy sample dataset&#10;data = {&#10;    'First Name': ['  John  ', 'Jane', '  Peter', 'JOHN', None],&#10;    'Last Name': ['Smith', 'Doe', 'Jones', 'Smith', 'Brown'],&#10;    'Age': [28, 34, None, 28, 45],&#10;    'Email': ['john@email.com', 'invalid-email', 'peter@test.org', 'john@email.com', None],&#10;    'Phone': ['123-456-7890', '(555) 123-4567', 'not-a-phone', '123.456.7890', '+1-800-555-0199'],&#10;    'Salary': ['$70,000', '80000', '$65,000.50', '$70,000', '€75,000'],&#10;    'Active': ['True', 'False', 'yes', 'TRUE', 'N'],&#10;    'Notes': ['  Important client  ', '', '   Follow up   ', None, 'VIP']&#10;}&#10;df = pd.DataFrame(data)&#10;&#10;# Clean the entire dataset with a single chain&#10;clean_df = (&#10;    sx(df)&#10;    .clean_column_names()                    # Standardize column names&#10;    .fill_missing(value='Unknown')           # Fill missing values&#10;    .remove_whitespace()                     # Clean whitespace&#10;    .remove_duplicates()                     # Remove duplicate rows&#10;    .standardize_booleans()                  # Convert boolean-like values&#10;    .extract_email()                         # Extract email addresses&#10;    .extract_phone_numbers()                 # Extract phone numbers&#10;    .extract_and_clean_numeric()             # Extract numeric values from strings&#10;    .drop_single_value_columns()             # Remove columns with only one value&#10;    .remove_outliers(method='iqr')           # Handle outliers&#10;    .format_for_display(                     # NEW: Format for presentation&#10;        rules={&#10;            'salary': {'type': 'currency', 'symbol': '$', 'decimals': 2},&#10;            'age': {'type': 'thousands'},&#10;        },&#10;        column_case='title'&#10;    )&#10;    .to_df()                                 # Return the cleaned, formatted DataFrame&#10;)&#10;&#10;print(clean_df.head())&#10;```&#10;&#10;---&#10;&#10;##  Complete API Reference&#10;&#10;### ️ Initialization&#10;&#10;```python&#10;import sanex as sx&#10;&#10;# Initialize with any DataFrame&#10;cleaner = sx(df)  # Works with pandas or polars DataFrames&#10;```&#10;&#10;###  Column Name Standardization&#10;&#10;Transform column names to consistent formats:&#10;&#10;```python&#10;# General column cleaning with case conversion&#10;.clean_column_names(case='snake')  # Options: 'snake', 'camel', 'pascal', 'kebab', 'title', 'lower', 'screaming_snake'&#10;&#10;# Specific case conversions&#10;.snakecase()                       # column_name&#10;.camelcase()                       # columnName  &#10;.pascalcase()                      # ColumnName&#10;.kebabcase()                       # column-name&#10;.titlecase()                       # Column Name&#10;.lowercase()                       # column name&#10;.screaming_snakecase()             # COLUMN_NAME&#10;```&#10;&#10;###  Data Deduplication&#10;&#10;Remove duplicate data efficiently:&#10;&#10;```python&#10;.remove_duplicates()               # Remove duplicate rows across all columns&#10;```&#10;&#10;### ❌ Missing Data Management&#10;&#10;Handle missing values with precision:&#10;&#10;```python&#10;# Fill missing values&#10;.fill_missing(value=0)                           # Fill all columns with 0&#10;.fill_missing(value='Unknown', subset=['name'])  # Fill specific columns&#10;&#10;# Drop missing values&#10;.drop_missing()                                  # Drop rows with any missing values&#10;.drop_missing(how='all')                         # Drop rows where all values are missing&#10;.drop_missing(thresh=3)                          # Keep rows with at least 3 non-null values&#10;.drop_missing(axis='columns')                    # Drop columns with missing values&#10;.drop_missing(subset=['name', 'email'])          # Consider only specific columns&#10;```&#10;&#10;###  Text and Whitespace Cleaning&#10;&#10;Clean and standardize text data:&#10;&#10;```python&#10;.remove_whitespace()                             # Remove leading/trailing whitespace&#10;.replace_text('old', 'new')                      # Replace text in all columns&#10;.replace_text('old', 'new', subset=['name'])     # Replace in specific columns&#10;.remove_punctuation()                            # Remove punctuation marks&#10;.remove_punctuation(subset=['description'])      # Remove from specific columns&#10;```&#10;&#10;### ️ Column Management&#10;&#10;Manage DataFrame structure:&#10;&#10;```python&#10;.drop_single_value_columns()                     # Remove columns with only one unique value&#10;.remove_unwanted_rows_and_cols()                 # Remove rows/cols with unwanted values&#10;.remove_unwanted_rows_and_cols(                  # Custom unwanted values&#10;    unwanted_values=['', 'N/A', 'NULL']&#10;)&#10;```&#10;&#10;###  Outlier Detection and Handling&#10;&#10;Sophisticated outlier management:&#10;&#10;```python&#10;# General outlier handling&#10;.handle_outliers()                               # Default: IQR method, factor=1.5&#10;.handle_outliers(method='zscore', factor=2.0)    # Z-score method&#10;.handle_outliers(subset=['salary', 'age'])       # Specific columns only&#10;&#10;# Cap outliers (replace with threshold values)&#10;.cap_outliers()                                  # Cap using IQR method&#10;.cap_outliers(method='zscore', factor=2.5)       # Cap using Z-score&#10;&#10;# Remove outlier rows entirely&#10;.remove_outliers()                               # Remove rows with outliers&#10;.remove_outliers(method='iqr', factor=1.5)       # Custom parameters&#10;```&#10;&#10;**Outlier Detection Methods:**&#10;- **IQR (Interquartile Range)**: `Q1 - factor*IQR` to `Q3 + factor*IQR`&#10;- **Z-Score**: Values beyond `factor` standard deviations from the mean&#10;&#10;###  Data Type Standardization&#10;&#10;Convert and standardize data types:&#10;&#10;```python&#10;# Boolean standardization&#10;.standardize_booleans()                          # Convert 'yes/no', 'true/false', etc.&#10;.standardize_booleans(&#10;    true_values=['yes', 'y', '1', 'true'],       # Custom true values&#10;    false_values=['no', 'n', '0', 'false'],     # Custom false values  &#10;    columns=['active', 'verified']              # Specific columns&#10;)&#10;```&#10;&#10;**Default Boolean Mappings:**&#10;- **True**: 'true', '1', 't', 'yes', 'y', 'on'&#10;- **False**: 'false', '0', 'f', 'no', 'n', 'off'&#10;&#10;###  Advanced Data Extraction&#10;&#10;Extract structured data from unstructured text:&#10;&#10;```python&#10;# Email extraction&#10;.extract_email()                                 # Extract emails from all columns&#10;.extract_email(subset=['contact_info'])          # From specific columns&#10;&#10;# Phone number extraction  &#10;.extract_phone_numbers()                         # Extract phone numbers&#10;.extract_phone_numbers(subset=['contact'])       # From specific columns&#10;&#10;# Numeric data extraction and cleaning&#10;.extract_and_clean_numeric()                     # Extract numbers from text&#10;.extract_and_clean_numeric(subset=['prices'])    # From specific columns&#10;&#10;# Custom regex extraction (interactive)&#10;.extract_with_regex()                            # Prompts for regex pattern&#10;.extract_with_regex(subset=['text_column'])      # From specific columns&#10;&#10;# Combined numeric cleaning&#10;.clean_numeric()                                 # Extract + outlier handling&#10;.clean_numeric(method='zscore', factor=2.0)      # Custom outlier parameters&#10;```&#10;&#10;###  Display / Presentation Formatting (NEW in 0.3.0)&#10;&#10;Format cleaned data for reports, dashboards, exports:&#10;&#10;```python&#10;.format_for_display(&#10;    rules={&#10;        'price': {'type': 'currency', 'symbol': '$', 'decimals': 2},&#10;        'growth': {'type': 'percentage', 'decimals': 1},&#10;        'volume': {'type': 'thousands'},&#10;        'description': {'type': 'truncate', 'length': 30},&#10;        'event_date': {'type': 'datetime', 'format': '%B %d, %Y'}&#10;    },&#10;    column_case='title'  # or None to preserve original column names&#10;)&#10;```&#10;&#10;Supported rule types:&#10;- `currency`: symbol + thousands + decimal precision&#10;- `percentage`: multiplies by 100 + suffix `%`&#10;- `thousands`: adds thousands separators, removes trailing `.0` for whole floats&#10;- `truncate`: shortens long text and appends `...`&#10;- `datetime`: parses and formats date/time strings&#10;&#10;You can also call the function directly:&#10;```python&#10;from sanex.functions import format_for_display&#10;formatted = format_for_display(df, rules=..., column_case='title')&#10;```&#10;&#10;###  Output&#10;&#10;```python&#10;.to_df()                                         # Return the cleaned DataFrame&#10;```&#10;&#10;---&#10;&#10;##  Advanced Usage Examples&#10;&#10;### Real-World Data Cleaning Pipeline&#10;&#10;```python&#10;import pandas as pd&#10;import sanex as sx&#10;&#10;# Load messy customer data&#10;df = pd.read_csv('messy_customer_data.csv')&#10;&#10;# Comprehensive cleaning + formatting pipeline&#10;clean_customers = (&#10;    sx(df)&#10;    .clean_column_names(case='snake')&#10;    .fill_missing(value='Not Provided')&#10;    .remove_whitespace()&#10;    .standardize_booleans(columns=['is_active', 'newsletter_opt_in'])&#10;    .extract_email(subset=['contact_info'])&#10;    .extract_phone_numbers(subset=['contact_info'])&#10;    .extract_and_clean_numeric(subset=['revenue', 'age'])&#10;    .remove_outliers(method='iqr', factor=2.0, subset=['revenue'])&#10;    .drop_single_value_columns()&#10;    .remove_duplicates()&#10;    .format_for_display(&#10;        rules={&#10;            'revenue': {'type': 'currency', 'symbol': '$', 'decimals': 2},&#10;            'age': {'type': 'thousands'},&#10;            'signup_date': {'type': 'datetime', 'format': '%Y-%m-%d'}&#10;        },&#10;        column_case='title'&#10;    )&#10;    .to_df()&#10;)&#10;```&#10;&#10;### Financial Data Processing&#10;&#10;```python&#10;financial_clean = (&#10;    sx(transactions_df)&#10;    .clean_column_names(case='snake')&#10;    .fill_missing(value=0, subset=['amount'])&#10;    .extract_and_clean_numeric(subset=['amount', 'fee'])&#10;    .standardize_booleans(subset=['is_recurring'])&#10;    .cap_outliers(method='zscore', factor=3.0, subset=['amount'])&#10;    .remove_whitespace()&#10;    .format_for_display(&#10;        rules={'amount': {'type': 'currency', 'symbol': '$', 'decimals': 2}},&#10;        column_case='title'&#10;    )&#10;    .to_df()&#10;)&#10;```&#10;&#10;### Survey Data Standardization&#10;&#10;```python&#10;survey_clean = (&#10;    sx(survey_df)&#10;    .clean_column_names(case='snake')&#10;    .standardize_booleans(&#10;        true_values=['Yes', 'Y', 'Agree', 'True', '1'],&#10;        false_values=['No', 'N', 'Disagree', 'False', '0']&#10;    )&#10;    .fill_missing(value='No Response')&#10;    .remove_whitespace()&#10;    .drop_single_value_columns()&#10;    .format_for_display(&#10;        rules={'age': {'type': 'thousands'}},&#10;        column_case='title'&#10;    )&#10;    .to_df()&#10;)&#10;```&#10;&#10;---&#10;&#10;##  Method Chaining Benefits&#10;&#10;Sanex's chainable API provides several advantages:&#10;&#10;1. **Readability**: Each step is clear and self-documenting&#10;2. **Maintainability**: Easy to add, remove, or reorder operations&#10;3. **Performance**: Optimized internal operations reduce memory overhead&#10;4. **Flexibility**: Mix and match operations based on your data's needs&#10;&#10;```python&#10;# Traditional approach (verbose and hard to follow)&#10;df = remove_duplicates(df)&#10;df = fill_missing(df, value='Unknown')&#10;df = standardize_booleans(df)&#10;df = remove_outliers(df, method='iqr')&#10;&#10;# Sanex approach (clean and readable)&#10;df = (sx(df)&#10;      .remove_duplicates()&#10;      .fill_missing(value='Unknown')&#10;      .standardize_booleans()&#10;      .remove_outliers(method='iqr')&#10;      .format_for_display(rules={'value': {'type': 'currency'}}, column_case='title')&#10;      .to_df())&#10;```&#10;&#10;---&#10;&#10;##  Performance Tips&#10;&#10;1. **Use polars for large datasets** - Sanex automatically optimizes for polars' performance&#10;2. **Chain operations efficiently** - Sanex minimizes intermediate copies&#10;3. **Specify subsets** - Process only the columns you need&#10;4. **Choose appropriate outlier methods** - IQR is faster, Z-score is more sensitive&#10;&#10;```python&#10;# Performance-optimized pipeline&#10;result = (&#10;    sx(large_df)&#10;    .remove_duplicates()&#10;    .drop_single_value_columns()&#10;    .fill_missing(value=0, subset=['numeric_cols'])&#10;    .remove_outliers(method='iqr', subset=['revenue'])&#10;    .format_for_display(rules={'revenue': {'type': 'currency'}}, column_case=None)&#10;    .to_df()&#10;)&#10;```&#10;&#10;---&#10;&#10;##  Testing and Quality Assurance&#10;&#10;Sanex includes comprehensive test coverage with 118+ test cases covering:&#10;&#10;- ✅ pandas and polars compatibility&#10;- ✅ Edge cases and error handling  &#10;- ✅ Performance optimization&#10;- ✅ Data integrity preservation&#10;- ✅ Type safety and validation&#10;- ✅ Presentation formatting (currency, percentage, thousands, truncation, datetime, column casing)&#10;&#10;Run tests locally:&#10;```bash&#10;git clone https://github.com/johntocci/sanex&#10;cd sanex&#10;pip install -e .[dev]&#10;pytest tests/&#10;```&#10;&#10;---&#10;&#10;##  Contributing&#10;&#10;We welcome contributions! Sanex is designed to be extensible and community-driven.&#10;&#10;### How to Contribute&#10;&#10;1. **Fork the repository** on GitHub&#10;2. **Create a feature branch**: `git checkout -b feature/amazing-feature`&#10;3. **Add your changes** with comprehensive tests&#10;4. **Follow the coding standards** (black formatting, type hints)&#10;5. **Run the test suite**: `pytest tests/`&#10;6. **Submit a pull request** with a clear description&#10;&#10;### Development Setup&#10;&#10;```bash&#10;# Clone and setup development environment&#10;git clone https://github.com/johntocci/sanex&#10;cd sanex&#10;pip install -e .[dev]&#10;&#10;# Run tests&#10;pytest tests/&#10;&#10;# Format code&#10;black src/ tests/&#10;```&#10;&#10;### Adding New Functions&#10;&#10;Sanex's modular architecture makes it easy to add new cleaning functions:&#10;&#10;1. Create your function in `src/sanex/functions/`&#10;2. Add it to the imports in `src/sanex/functions/__init__.py`&#10;3. Add a corresponding method to the `Sanex` class&#10;4. Write comprehensive tests in `tests/`&#10;&#10;---&#10;&#10;##  Changelog&#10;&#10;### Version 0.3.0&#10;- ✨ Added `format_for_display` function + chain method for presentation formatting&#10;- ✨ Added support for currency, percentage, thousands, truncate, datetime formatting&#10;- ✨ Title-case header option integrated into formatting step&#10;-  Refactored internal formatting for pandas + polars parity&#10;- ✅ Expanded test suite (now 118+ tests) including display formatting&#10;- ⚡ Improved thousands formatting (no trailing .0 on whole floats)&#10;&#10;### Version 0.2.0&#10;- ✨ Added comprehensive data extraction capabilities&#10;- ✨ Enhanced outlier detection with multiple methods&#10;- ✨ Improved text processing and punctuation removal&#10;-  Fixed boolean standardization edge cases&#10;-  Resolved missing data handling in complex workflows&#10;- ⚡ Performance optimizations for large datasets&#10;-  Comprehensive documentation updates&#10;&#10;### Version 0.1.0&#10;-  Initial release with core cleaning functionality&#10;-  Chainable API implementation&#10;-  pandas and polars support&#10;&#10;---&#10;&#10;##  License&#10;&#10;This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.&#10;&#10;---&#10;&#10;##  Acknowledgments&#10;&#10;- Built with ❤️ for the data science community&#10;- Inspired by the need for simple, powerful data cleaning tools&#10;- Thanks to all contributors and users who help improve Sanex&#10;&#10;---&#10;&#10;&lt;div align=&quot;center&quot;&gt;&#10;&#10;**Made with ❤️ by [John Tocci](https://github.com/johntocci)**&#10;&#10;[⭐ Star us on GitHub](https://github.com/johntocci/sanex) | [ Report Issues](https://github.com/johntocci/sanex/issues) | [ Request Features](https://github.com/johntocci/sanex/issues)&#10;&#10;&lt;/div&gt;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>